{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 40 records\n",
    "xs0 = np.loadtxt('40ARs/M_Car1_aug_shs0.txt')\n",
    "xs1 = np.loadtxt('40ARs/M_Car1_aug_shs1.txt')\n",
    "xs2 = np.loadtxt('40ARs/M_Car1_aug_shs2.txt')\n",
    "xs3 = np.loadtxt('40ARs/M_Car1_aug_shs3.txt')\n",
    "xs = np.append(xs0, xs1, axis=0)\n",
    "xs = np.append(xs, xs2, axis=0)\n",
    "xs = np.append(xs, xs3, axis=0)\n",
    "\n",
    "ys = [0] * 10\n",
    "ys.extend([1] * 10)\n",
    "ys.extend([2] * 10)\n",
    "ys.extend([3] * 10)\n",
    "ys = np.array(ys)\n",
    "\n",
    "X.append(xs)\n",
    "Y.append(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 400 records\n",
    "xs0 = np.loadtxt('400ARs/M_Car1_aug_shs0.txt')\n",
    "xs1 = np.loadtxt('400ARs/M_Car1_aug_shs1.txt')\n",
    "xs2 = np.loadtxt('400ARs/M_Car1_aug_shs2.txt')\n",
    "xs3 = np.loadtxt('400ARs/M_Car1_aug_shs3.txt')\n",
    "xs = np.append(xs0, xs1, axis=0)\n",
    "xs = np.append(xs, xs2, axis=0)\n",
    "xs = np.append(xs, xs3, axis=0)\n",
    "\n",
    "ys = [0] * 100\n",
    "ys.extend([1] * 100)\n",
    "ys.extend([2] * 100)\n",
    "ys.extend([3] * 100)\n",
    "ys = np.array(ys)\n",
    "\n",
    "X.append(xs)\n",
    "Y.append(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 800 records\n",
    "xs0 = np.loadtxt('800ARs/M_Car1_aug_shs0.txt')\n",
    "xs1 = np.loadtxt('800ARs/M_Car1_aug_shs1.txt')\n",
    "xs2 = np.loadtxt('800ARs/M_Car1_aug_shs2.txt')\n",
    "xs3 = np.loadtxt('800ARs/M_Car1_aug_shs3.txt')\n",
    "xs = np.append(xs0, xs1, axis=0)\n",
    "xs = np.append(xs, xs2, axis=0)\n",
    "xs = np.append(xs, xs3, axis=0)\n",
    "\n",
    "ys = [0] * 200\n",
    "ys.extend([1] * 200)\n",
    "ys.extend([2] * 200)\n",
    "ys.extend([3] * 200)\n",
    "ys = np.array(ys)\n",
    "\n",
    "X.append(xs)\n",
    "Y.append(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1600 records\n",
    "xs0 = np.loadtxt('1600ARs/M_Car1_aug_shs0.txt')\n",
    "xs1 = np.loadtxt('1600ARs/M_Car1_aug_shs1.txt')\n",
    "xs2 = np.loadtxt('1600ARs/M_Car1_aug_shs2.txt')\n",
    "xs3 = np.loadtxt('1600ARs/M_Car1_aug_shs3.txt')\n",
    "xs = np.append(xs0, xs1, axis=0)\n",
    "xs = np.append(xs, xs2, axis=0)\n",
    "xs = np.append(xs, xs3, axis=0)\n",
    "\n",
    "ys = [0] * 400\n",
    "ys.extend([1] * 400)\n",
    "ys.extend([2] * 400)\n",
    "ys.extend([3] * 400)\n",
    "ys = np.array(ys)\n",
    "\n",
    "X.append(xs)\n",
    "Y.append(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3200 records\n",
    "xs0 = np.loadtxt('3200ARs/M_Car1_aug_shs0.txt')\n",
    "xs1 = np.loadtxt('3200ARs/M_Car1_aug_shs1.txt')\n",
    "xs2 = np.loadtxt('3200ARs/M_Car1_aug_shs2.txt')\n",
    "xs3 = np.loadtxt('3200ARs/M_Car1_aug_shs3.txt')\n",
    "xs = np.append(xs0, xs1, axis=0)\n",
    "xs = np.append(xs, xs2, axis=0)\n",
    "xs = np.append(xs, xs3, axis=0)\n",
    "\n",
    "ys = [0] * 800\n",
    "ys.extend([1] * 800)\n",
    "ys.extend([2] * 800)\n",
    "ys.extend([3] * 800)\n",
    "ys = np.array(ys)\n",
    "\n",
    "X.append(xs)\n",
    "Y.append(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4000 records\n",
    "xs0 = np.loadtxt('4000ARs/M_Car1_aug_shs0.txt')\n",
    "xs1 = np.loadtxt('4000ARs/M_Car1_aug_shs1.txt')\n",
    "xs2 = np.loadtxt('4000ARs/M_Car1_aug_shs2.txt')\n",
    "xs3 = np.loadtxt('4000ARs/M_Car1_aug_shs3.txt')\n",
    "xs = np.append(xs0, xs1, axis=0)\n",
    "xs = np.append(xs, xs2, axis=0)\n",
    "xs = np.append(xs, xs3, axis=0)\n",
    "\n",
    "ys = [0] * 1000\n",
    "ys.extend([1] * 1000)\n",
    "ys.extend([2] * 1000)\n",
    "ys.extend([3] * 1000)\n",
    "ys = np.array(ys)\n",
    "\n",
    "X.append(xs)\n",
    "Y.append(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_split = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "Cs = [1.1, 1.3, 1.7, 1.9]\n",
    "gammas = [0.012, 0.014, 0.016, 0.018]\n",
    "accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sample :: 0.2\n",
      "\n",
      "Sample size :: 40\n",
      "[[ 0.21875  0.21875  0.21875  0.21875]\n",
      " [ 0.21875  0.21875  0.21875  0.21875]\n",
      " [ 0.21875  0.21875  0.21875  0.21875]\n",
      " [ 0.21875  0.21875  0.21875  0.21875]]\n",
      "\n",
      "Sample size :: 400\n",
      "[[ 0.384375  0.40625   0.390625  0.378125]\n",
      " [ 0.409375  0.403125  0.396875  0.390625]\n",
      " [ 0.4125    0.403125  0.396875  0.390625]\n",
      " [ 0.4125    0.403125  0.396875  0.390625]]\n",
      "\n",
      "Sample size :: 800\n",
      "[[ 0.434375   0.440625   0.4453125  0.4375   ]\n",
      " [ 0.453125   0.4515625  0.45625    0.4453125]\n",
      " [ 0.453125   0.4546875  0.45625    0.4453125]\n",
      " [ 0.453125   0.4546875  0.45625    0.4453125]]\n",
      "\n",
      "Sample size :: 1600\n",
      "[[ 0.5640625   0.56796875  0.5703125   0.55625   ]\n",
      " [ 0.59609375  0.590625    0.58828125  0.5796875 ]\n",
      " [ 0.6125      0.6         0.59609375  0.58125   ]\n",
      " [ 0.6125      0.60078125  0.59609375  0.58125   ]]\n",
      "\n",
      "Sample size :: 3200\n",
      "[[ 0.75742188  0.74765625  0.73867187  0.7296875 ]\n",
      " [ 0.76757812  0.7546875   0.7453125   0.734375  ]\n",
      " [ 0.77460938  0.75859375  0.746875    0.7359375 ]\n",
      " [ 0.77460938  0.759375    0.746875    0.7359375 ]]\n",
      "\n",
      "Sample size :: 4000\n",
      "[[ 0.82875    0.830625   0.826875   0.8240625]\n",
      " [ 0.843125   0.840625   0.836875   0.83     ]\n",
      " [ 0.85       0.8471875  0.839375   0.830625 ]\n",
      " [ 0.8503125  0.8471875  0.839375   0.830625 ]]\n",
      "\n",
      "Train sample :: 0.3\n",
      "\n",
      "Sample size :: 40\n",
      "[[ 0.25        0.25        0.21428571  0.21428571]\n",
      " [ 0.32142857  0.32142857  0.25        0.25      ]\n",
      " [ 0.32142857  0.32142857  0.25        0.25      ]\n",
      " [ 0.32142857  0.32142857  0.25        0.25      ]]\n",
      "\n",
      "Sample size :: 400\n",
      "[[ 0.4         0.39642857  0.39642857  0.41071429]\n",
      " [ 0.40714286  0.42142857  0.40714286  0.41071429]\n",
      " [ 0.42142857  0.42142857  0.41071429  0.41071429]\n",
      " [ 0.42142857  0.42142857  0.41071429  0.41071429]]\n",
      "\n",
      "Sample size :: 800\n",
      "[[ 0.5         0.50178571  0.50535714  0.50892857]\n",
      " [ 0.50357143  0.50357143  0.5         0.51428571]\n",
      " [ 0.50714286  0.5         0.5         0.51607143]\n",
      " [ 0.50535714  0.5         0.5         0.51607143]]\n",
      "\n",
      "Sample size :: 1600\n",
      "[[ 0.64107143  0.63482143  0.63303571  0.62946429]\n",
      " [ 0.65714286  0.64642857  0.64107143  0.63660714]\n",
      " [ 0.66607143  0.65089286  0.64553571  0.63839286]\n",
      " [ 0.66607143  0.65089286  0.64553571  0.63839286]]\n",
      "\n",
      "Sample size :: 3200\n",
      "[[ 0.81919643  0.81830357  0.81026786  0.796875  ]\n",
      " [ 0.83705357  0.82946429  0.81741071  0.80580357]\n",
      " [ 0.84107143  0.83303571  0.82142857  0.80803571]\n",
      " [ 0.84107143  0.83303571  0.82098214  0.80803571]]\n",
      "\n",
      "Sample size :: 4000\n",
      "[[ 0.88464286  0.88321429  0.87857143  0.87642857]\n",
      " [ 0.8975      0.89285714  0.88678571  0.88142857]\n",
      " [ 0.90571429  0.89964286  0.88785714  0.88214286]\n",
      " [ 0.90678571  0.89964286  0.88785714  0.88214286]]\n",
      "\n",
      "Train sample :: 0.4\n",
      "\n",
      "Sample size :: 40\n",
      "[[ 0.08333333  0.08333333  0.08333333  0.08333333]\n",
      " [ 0.08333333  0.08333333  0.08333333  0.08333333]\n",
      " [ 0.08333333  0.08333333  0.08333333  0.08333333]\n",
      " [ 0.08333333  0.08333333  0.08333333  0.08333333]]\n",
      "\n",
      "Sample size :: 400\n",
      "[[ 0.425       0.4125      0.39583333  0.40833333]\n",
      " [ 0.425       0.41666667  0.42083333  0.4125    ]\n",
      " [ 0.43333333  0.425       0.41666667  0.4125    ]\n",
      " [ 0.43333333  0.425       0.41666667  0.4125    ]]\n",
      "\n",
      "Sample size :: 800\n",
      "[[ 0.55833333  0.55208333  0.54583333  0.54166667]\n",
      " [ 0.55625     0.55        0.54583333  0.54375   ]\n",
      " [ 0.56041667  0.55625     0.54791667  0.54375   ]\n",
      " [ 0.56041667  0.55625     0.54791667  0.54375   ]]\n",
      "\n",
      "Sample size :: 1600\n",
      "[[ 0.67604167  0.66770833  0.66041667  0.65833333]\n",
      " [ 0.70104167  0.68958333  0.67708333  0.66875   ]\n",
      " [ 0.72291667  0.70625     0.68333333  0.671875  ]\n",
      " [ 0.72395833  0.70625     0.68333333  0.671875  ]]\n",
      "\n",
      "Sample size :: 3200\n",
      "[[ 0.8625      0.85364583  0.84114583  0.83072917]\n",
      " [ 0.88489583  0.87083333  0.8578125   0.8421875 ]\n",
      " [ 0.89583333  0.87760417  0.86302083  0.84635417]\n",
      " [ 0.89635417  0.87864583  0.86354167  0.84635417]]\n",
      "\n",
      "Sample size :: 4000\n",
      "[[ 0.93416667  0.93208333  0.92666667  0.91625   ]\n",
      " [ 0.94333333  0.93708333  0.93333333  0.92041667]\n",
      " [ 0.94416667  0.94083333  0.93375     0.92083333]\n",
      " [ 0.94416667  0.94083333  0.93375     0.92083333]]\n",
      "\n",
      "Train sample :: 0.5\n",
      "\n",
      "Sample size :: 40\n",
      "[[ 0.1   0.15  0.15  0.15]\n",
      " [ 0.15  0.15  0.15  0.15]\n",
      " [ 0.15  0.15  0.15  0.15]\n",
      " [ 0.15  0.15  0.15  0.15]]\n",
      "\n",
      "Sample size :: 400\n",
      "[[ 0.455  0.48   0.47   0.485]\n",
      " [ 0.475  0.485  0.48   0.485]\n",
      " [ 0.465  0.46   0.475  0.485]\n",
      " [ 0.465  0.46   0.475  0.485]]\n",
      "\n",
      "Sample size :: 800\n",
      "[[ 0.555   0.5575  0.5525  0.55  ]\n",
      " [ 0.555   0.56    0.5525  0.5575]\n",
      " [ 0.5675  0.5675  0.5525  0.5575]\n",
      " [ 0.5675  0.5675  0.5525  0.5575]]\n",
      "\n",
      "Sample size :: 1600\n",
      "[[ 0.70625  0.7025   0.695    0.69125]\n",
      " [ 0.72875  0.7225   0.715    0.7    ]\n",
      " [ 0.745    0.73375  0.71875  0.70125]\n",
      " [ 0.74625  0.735    0.7175   0.70125]]\n",
      "\n",
      "Sample size :: 3200\n",
      "[[ 0.925     0.93      0.92375   0.9075  ]\n",
      " [ 0.933125  0.93375   0.925     0.90875 ]\n",
      " [ 0.939375  0.935     0.926875  0.90875 ]\n",
      " [ 0.940625  0.93625   0.926875  0.90875 ]]\n",
      "\n",
      "Sample size :: 4000\n",
      "[[ 0.951   0.9515  0.949   0.9455]\n",
      " [ 0.9605  0.96    0.9555  0.9525]\n",
      " [ 0.966   0.9645  0.9585  0.9545]\n",
      " [ 0.9675  0.9645  0.9585  0.9545]]\n",
      "\n",
      "Train sample :: 0.6\n",
      "\n",
      "Sample size :: 40\n",
      "[[ 0.25    0.1875  0.1875  0.1875]\n",
      " [ 0.1875  0.25    0.1875  0.1875]\n",
      " [ 0.1875  0.25    0.1875  0.1875]\n",
      " [ 0.1875  0.25    0.1875  0.1875]]\n",
      "\n",
      "Sample size :: 400\n",
      "[[ 0.48125  0.4875   0.48125  0.50625]\n",
      " [ 0.49375  0.4875   0.5      0.50625]\n",
      " [ 0.5125   0.50625  0.5      0.50625]\n",
      " [ 0.5125   0.50625  0.5      0.50625]]\n",
      "\n",
      "Sample size :: 800\n",
      "[[ 0.615625  0.6       0.603125  0.6     ]\n",
      " [ 0.609375  0.603125  0.60625   0.60625 ]\n",
      " [ 0.621875  0.6125    0.60625   0.60625 ]\n",
      " [ 0.621875  0.6125    0.60625   0.60625 ]]\n",
      "\n",
      "Sample size :: 1600\n",
      "[[ 0.765625   0.75625    0.75       0.7375   ]\n",
      " [ 0.7859375  0.7765625  0.76875    0.7484375]\n",
      " [ 0.7984375  0.7859375  0.775      0.746875 ]\n",
      " [ 0.7984375  0.7859375  0.775      0.746875 ]]\n",
      "\n",
      "Sample size :: 3200\n",
      "[[ 0.93984375  0.934375    0.9296875   0.91796875]\n",
      " [ 0.9484375   0.94296875  0.93515625  0.921875  ]\n",
      " [ 0.953125    0.94453125  0.93828125  0.92265625]\n",
      " [ 0.9546875   0.9453125   0.93828125  0.92265625]]\n",
      "\n",
      "Sample size :: 4000\n",
      "[[ 0.981875  0.98125   0.980625  0.973125]\n",
      " [ 0.985625  0.984375  0.98125   0.974375]\n",
      " [ 0.98875   0.9875    0.981875  0.975   ]\n",
      " [ 0.98875   0.9875    0.981875  0.975   ]]\n",
      "\n",
      "Train sample :: 0.7\n",
      "\n",
      "Sample size :: 40\n",
      "[[ 0.25  0.25  0.25  0.25]\n",
      " [ 0.25  0.25  0.25  0.25]\n",
      " [ 0.25  0.25  0.25  0.25]\n",
      " [ 0.25  0.25  0.25  0.25]]\n",
      "\n",
      "Sample size :: 400\n",
      "[[ 0.4         0.39166667  0.39166667  0.4       ]\n",
      " [ 0.425       0.425       0.41666667  0.41666667]\n",
      " [ 0.425       0.43333333  0.425       0.41666667]\n",
      " [ 0.425       0.43333333  0.425       0.41666667]]\n",
      "\n",
      "Sample size :: 800\n",
      "[[ 0.5875      0.6         0.6         0.59583333]\n",
      " [ 0.60416667  0.60833333  0.60416667  0.6       ]\n",
      " [ 0.625       0.61666667  0.6125      0.60416667]\n",
      " [ 0.62916667  0.6125      0.6125      0.60416667]]\n",
      "\n",
      "Sample size :: 1600\n",
      "[[ 0.84583333  0.83958333  0.83333333  0.82291667]\n",
      " [ 0.87083333  0.86041667  0.84791667  0.8375    ]\n",
      " [ 0.87291667  0.86458333  0.85208333  0.8375    ]\n",
      " [ 0.87083333  0.86458333  0.85208333  0.8375    ]]\n",
      "\n",
      "Sample size :: 3200\n",
      "[[ 0.96770833  0.96666667  0.96354167  0.95520833]\n",
      " [ 0.96979167  0.971875    0.96979167  0.959375  ]\n",
      " [ 0.975       0.97291667  0.97083333  0.96041667]\n",
      " [ 0.975       0.97291667  0.97083333  0.96041667]]\n",
      "\n",
      "Sample size :: 4000\n",
      "[[ 0.98        0.97833333  0.97416667  0.9725    ]\n",
      " [ 0.98416667  0.98083333  0.9775      0.97333333]\n",
      " [ 0.98583333  0.98166667  0.97833333  0.97416667]\n",
      " [ 0.98666667  0.98166667  0.97833333  0.97416667]]\n",
      "\n",
      "Train sample :: 0.8\n",
      "\n",
      "Sample size :: 40\n",
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "\n",
      "Sample size :: 400\n",
      "[[ 0.55    0.55    0.5125  0.5125]\n",
      " [ 0.5625  0.55    0.55    0.525 ]\n",
      " [ 0.5625  0.55    0.55    0.525 ]\n",
      " [ 0.5625  0.55    0.55    0.525 ]]\n",
      "\n",
      "Sample size :: 800\n",
      "[[ 0.60625  0.59375  0.5875   0.58125]\n",
      " [ 0.63125  0.6125   0.60625  0.60625]\n",
      " [ 0.6375   0.6125   0.60625  0.60625]\n",
      " [ 0.64375  0.6125   0.60625  0.60625]]\n",
      "\n",
      "Sample size :: 1600\n",
      "[[ 0.84375   0.834375  0.8       0.8     ]\n",
      " [ 0.865625  0.846875  0.821875  0.80625 ]\n",
      " [ 0.875     0.859375  0.83125   0.81875 ]\n",
      " [ 0.875     0.859375  0.83125   0.81875 ]]\n",
      "\n",
      "Sample size :: 3200\n",
      "[[ 0.96875    0.96875    0.9703125  0.9671875]\n",
      " [ 0.9734375  0.971875   0.9703125  0.96875  ]\n",
      " [ 0.9734375  0.975      0.971875   0.96875  ]\n",
      " [ 0.975      0.975      0.971875   0.96875  ]]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size :: 4000\n",
      "[[ 0.98625  0.9875   0.98875  0.9825 ]\n",
      " [ 0.98875  0.99     0.99     0.98375]\n",
      " [ 0.99125  0.99125  0.99     0.98375]\n",
      " [ 0.99125  0.99125  0.99     0.98375]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_size in sample_split:\n",
    "    print \"Train sample ::\", train_size\n",
    "    print\n",
    "    for xs, ys in zip(X, Y):\n",
    "        train_x, test_x, train_y, test_y = train_test_split(xs, ys, train_size=train_size)\n",
    "        accs = []\n",
    "        for C in Cs:\n",
    "            test_acc = []\n",
    "            for gamma in gammas:\n",
    "                rbf_svc = svm.SVC(kernel='rbf', gamma=gamma, C=C).fit(train_x, train_y)\n",
    "                test_acc.append(accuracy_score(test_y, rbf_svc.predict(test_x)))\n",
    "            accs.append(test_acc)\n",
    "        print \"Sample size ::\", len(ys)\n",
    "        print np.matrix(accs)\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
